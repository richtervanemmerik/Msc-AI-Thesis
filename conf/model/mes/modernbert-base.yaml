module:
  _target_: models.pl_modules.BasePLModule
  RAdam:
    _target_: torch.optim.RAdam
    lr: 2e-5
  Adafactor:
    _target_: transformers.Adafactor
    lr: 3e-5  ## 3e-5
    weight_decay: 0.01
    scale_parameter: False
    relative_step: False
  lr_scheduler: 
    num_warmup_steps: 900 ## {450, 900, 1200}
    num_training_steps: 12000
  opt: "Adafactor" #RAdam
  model:
    _target_: models.model_mes.Maverick_mes
    language_model: "ModernBERT-base"
    huggingface_model_name: "answerdotai/ModernBERT-base"
    freeze_encoder: False
    unfrozen_layers: 18
    span_representation: "concat_start_end"
    mention_treshold: 0.5
    singleton_loss: False
    singleton_detector: False
    entity2id_path: "/home/azureuser/cloudfiles/code/Users/rvanemmerik1/maverick-coref/maverick/data/Wikidata/knowledge_graphs/entity2id.txt"
    embeddings_path: "/home/azureuser/cloudfiles/code/Users/rvanemmerik1/maverick-coref/maverick/data/Wikidata/embeddings/dimension_100/transe/entity2vec.bin"
    relation_path: "/home/azureuser/cloudfiles/code/Users/rvanemmerik1/maverick-coref/maverick/data/Wikidata/embeddings/dimension_100/transe/relation2vec.bin"